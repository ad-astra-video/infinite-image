services:
  register-worker:
    build:
      context: ./register
      dockerfile: Dockerfile.register_worker
    container_name: byoc-stream-register-worker
    environment:
      - "ORCH_URL=https://${ORCH_SERVICE_ADDR}"
      - "ORCH_SECRET=${ORCH_SECRET}"
      - "CAPABILITY_NAME=${CAPABILITY_NAME}"
      - "CAPABILITY_DESCRIPTION=${CAPABILITY_DESCRIPTION}"
      - "CAPABILITY_URL=${CAPABILITY_URL}"
      - "CAPABILITY_PRICE_PER_UNIT=${CAPABILITY_PRICE_PER_UNIT}"
      - "CAPABILITY_PRICE_SCALING=${CAPABILITY_PRICE_SCALING}"
      - "CAPABILITY_CAPACITY=${CAPABILITY_CAPACITY}"
  ai-runner:
    image: ${RUNNER_IMAGE}
    container_name: byoc-stream-runner
    runtime: nvidia
    environment:
      VERSION: 0.14.5
      HF_TOKEN: ${HF_TOKEN}
    #use this to limit the ephemeral port range used by webrtc if needed
    #sysctls:
    #    net.ipv4.ip_local_port_range: "44000 44100"
    ports:
      - 8888:8000
    volumes:
      #example to include models in the runner
      - /models2:/root/.cache/huggingface/hub
      ##development examples##
      #- C:\dev\pytrickle\pytrickle:/opt/venv/lib/python3.12/site-packages/pytrickle
#  runner-proxy:
#    image: caddy:latest
#    container_name: byoc-stream-runner-proxy
#    ports:
#      - 9099:9099
#    volumes:
#      - ./proxy/Caddyfile:/etc/caddy/Caddyfile
#    environment:
#      - HOST=${HOST}
#      - AI_RUNNER_PORT=${AI_RUNNER_PORT}
#      - AI_RUNNER_HTTPS_EMAIL=${AI_RUNNER_HTTPS_EMAIL}
networks:
  default:
    name: byoc-stream
    external: true
